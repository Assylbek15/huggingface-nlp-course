{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Assylbek15/huggingface-nlp-course/blob/main/chapter01_introduction/transformers_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w40EA-XL6sqW"
      },
      "source": [
        "# Transformers, what can they do?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG2ee12d6sqZ"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vF-dSapd6sqZ"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0wGRlm26sqa",
        "outputId": "36f59739-53f5-4df6-ee72-3304c4b6f3e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.5876696705818176}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "\n",
        "# The `pipeline(\"sentiment-analysis\")` line automatically:\n",
        "# - Loads a pretrained model (usually `distilbert-base-uncased-finetuned-sst-2-english`)\n",
        "# - Sets up the tokenizer and model for inference\n",
        "# - Preprocesses the input, runs it through the model, and postprocesses the result\n",
        "\n",
        "# input -> any sentence ,\n",
        "# output -> (positive/negative) & confidence score\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"No more buses, no more waiting — just me and my Lamborghini in the fast lane of life.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxCNG5rK6sqb",
        "outputId": "7f8a6ce8-41fd-46f8-f34e-9006e6d6c42c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "classifier(\n",
        "    [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\"Wow, you really did that.\")\n",
        "# Sarcastic or impressed?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMKZmWrY72no",
        "outputId": "66ede54f-4d2f-4da2-d206-0069f804fee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9997573494911194}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snABBXkX6sqb",
        "outputId": "33ce2ada-af8c-4c10-af63-3a07a98b2528",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': \"We're experimenting with reinforcement learning algorithms to optimize robotic movement.\",\n",
              " 'labels': ['machine learning', 'robotics', 'healthcare'],\n",
              " 'scores': [0.6172025799751282, 0.37971267104148865, 0.0030847135931253433]}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# ➤ zero-shot-classification → no fine-tuning needed\n",
        "# ➤ model = multi-label classifier (e.g., bart-large-mnli)\n",
        "# ➤ input = unlabeled text\n",
        "# ➤ candidate_labels = custom label set\n",
        "# ➤ output → ranked labels by relevance + scores\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"We're experimenting with reinforcement learning algorithms to optimize robotic movement.\",\n",
        "    candidate_labels=[\"machine learning\", \"robotics\", \"healthcare\"],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Fwm-UH16sqc",
        "outputId": "7c55dfd0-43d9-4b8b-dba1-412e7912ad3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"In this course, we will teach you how to define and quantify your brand and who you are, a new look at traditional marketing and marketing and social media platforms and the benefits, and failures, you're after.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# ➤ text-generation → generates continuation for a given prompt\n",
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"In this course, we will teach you how to\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFjUu0KX6sqc",
        "outputId": "1d871c1b-d2a3-4809-9569-05ea75e6a338",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'In this course, we will teach you how to convert the world to you through a learning tool.\\n\\n\\n\\nThe following questions, questions and'},\n",
              " {'generated_text': 'In this course, we will teach you how to create effective and responsive web content solutions to all of these issues.\\n\\n\\n\\n\\nThis course'}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# ➤ hyperparameters:\n",
        "#     ↳ max_length = 30 → total number of tokens (prompt + generated)\n",
        "#     ↳ num_return_sequences = 2 → generate 2 different completions\n",
        "# ➤ other optional params (not used here):\n",
        "#     ↳ temperature → controls randomness (↑ temp = more creative)\n",
        "#     ↳ top_k / top_p → controls sampling diversity\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "generator(\n",
        "    \"In this course, we will teach you how to\",\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNP96Vbs6sqc",
        "outputId": "2e20cb08-67fc-4e09-85fc-7dcdbbfc365d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.19370311498641968,\n",
              "  'token': 2621,\n",
              "  'token_str': 'summer',\n",
              "  'sequence': 'i am currently applying for a summer internship.'},\n",
              " {'score': 0.10473033785820007,\n",
              "  'token': 11643,\n",
              "  'token_str': 'modeling',\n",
              "  'sequence': 'i am currently applying for a modeling internship.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# ➤ fill-mask → predicts masked word in a sentence\n",
        "# ➤ uses masked language models (e.g., BERT)\n",
        "# ➤ <mask> = special token the model will fill\n",
        "# ➤ top_k = number of predictions returned (ranked by confidence)\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
        "unmasker(\"I am currently applying for a [MASK] internship.\", top_k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MF5sbdBl6sqd",
        "outputId": "d774253f-af6f-4a59-ba95-1e0ab5f2bbbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': np.float32(0.9991107),\n",
              "  'word': 'Barack Obama',\n",
              "  'start': 0,\n",
              "  'end': 12},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': np.float32(0.951369),\n",
              "  'word': 'Harvard University',\n",
              "  'start': 24,\n",
              "  'end': 42},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': np.float32(0.99944824),\n",
              "  'word': 'Washington',\n",
              "  'start': 54,\n",
              "  'end': 64},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': np.float32(0.999298),\n",
              "  'word': 'Chicago',\n",
              "  'start': 83,\n",
              "  'end': 90},\n",
              " {'entity_group': 'PER',\n",
              "  'score': np.float32(0.99817735),\n",
              "  'word': 'Michelle Obama',\n",
              "  'start': 96,\n",
              "  'end': 110}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# ➤ ner = Named Entity Recognition → detects entities in text\n",
        "# ➤ grouped_entities=True → combines subword tokens into full entities\n",
        "# ➤ output = list of detected entities with:\n",
        "#     ↳ entity_group (e.g., PER, ORG, LOC)\n",
        "#     ↳ word (actual entity text)\n",
        "#     ↳ score (confidence), start/end (char positions)\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "ner(\"Barack Obama studied at Harvard University, worked in Washington, and now lives in Chicago with Michelle Obama.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjQwE6AB6sqd",
        "outputId": "4ec9fae7-bba4-42e7-beed-0d23eab9aa42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.5476713180541992,\n",
              " 'start': 51,\n",
              " 'end': 70,\n",
              " 'answer': 'Stanford University'}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# ➤ question-answering → extract answer from given context\n",
        "# ➤ input = question + context paragraph\n",
        "# ➤ model scans context and returns:\n",
        "#     ↳ answer (text span)\n",
        "#     ↳ score (confidence), start/end (char positions)\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\")\n",
        "question_answerer(\n",
        "    question=\"Which university did Alice graduate from?\",\n",
        "    context=\"Alice completed her studies in computer science at Stanford University in 2022.\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_Agasvz6sqd",
        "outputId": "d519fc8f-6e54-4984-bd26-70db54f65cd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' Raskolnikov had a terrible dream about beating a horse to death with crowbars . He woke up drenched in sweat, heart pounding, the scene burned into his mind . The idea that he was above morality, that he could commit a crime for a higher purpose — it now felt hollow .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# summarizes given text\n",
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    Raskolnikov had a terrible dream. He was a little boy, walking with his father through a desolate village.\n",
        "    The sky was low and grey, and everything was silent. Suddenly, a drunken group of peasants appeared, laughing\n",
        "    and shouting. They had a cart with an old, broken-down mare hitched to it. Laughing cruelly, they tried to\n",
        "    force the exhausted animal to run. They whipped it, beat it with crowbars, screamed at it as it staggered and fell.\n",
        "    The boy sobbed and begged them to stop, but they only laughed louder. The horse was beaten to death, its eyes\n",
        "    wide with terror and blood on its flanks, while the little boy screamed and cried, powerless. Then he woke up,\n",
        "    drenched in sweat, heart pounding, the scene burned into his mind.\n",
        "\n",
        "    This dream haunted him. It was more than just a nightmare; it was a symbol, something deeper. He paced the floor,\n",
        "    wrestling with the images and the weight of what he had done. Murder was not the clean, rational act he had imagined.\n",
        "    It was chaos. It left behind blood, terror, and voices in the night. The idea that he was above morality,\n",
        "    that he could commit a crime for a higher purpose — it now felt hollow. And yet, he could not let go of it.\n",
        "    He clung to the belief that his theory had merit, even as guilt gnawed at the edges of his soul. His intellect\n",
        "    and his conscience were at war, and he was the battlefield.\n",
        "    \"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Qt6ZV0U6sqd",
        "outputId": "e61ccec3-d84b-489b-ca1f-b49737b0c820",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'This course is produced by Hugging Face.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# translate\n",
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
        "translator(\"Ce cours est produit par Hugging Face.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "# Load the pipeline\n",
        "image_classifier = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n",
        "\n",
        "# Load image from URL\n",
        "url = \"https://images.unsplash.com/photo-1647725280666-bb7f94a15d69?q=80&w=687&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "# Run classification\n",
        "result = image_classifier(image)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjJY67kjkad0",
        "outputId": "668386b0-489d-4e43-860d-601f41a812e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'brambling, Fringilla montifringilla', 'score': 0.09883487224578857}, {'label': 'goldfinch, Carduelis carduelis', 'score': 0.08341510593891144}, {'label': 'indigo bunting, indigo finch, indigo bird, Passerina cyanea', 'score': 0.07287737727165222}, {'label': 'house finch, linnet, Carpodacus mexicanus', 'score': 0.04017132148146629}, {'label': 'sulphur butterfly, sulfur butterfly', 'score': 0.012354685924947262}]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}